{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLFlow Experiment\n",
    "\n",
    "How to efficiently run multiple ML experiments using `dutil` and `mlflow`:\n",
    "- make explicit dependencies between the tasks in the pipeline\n",
    "- run the pipeline with different parameters \n",
    "- record and visualize metrics from multiple runs\n",
    "- cache intermediate data and models\n",
    "\n",
    "About:\n",
    "- The pipeline is set in `mlflow_experiment.py`\n",
    "- To see MLFlow metrics summary, run `mlflow ui` in the shell (from this folder)\n",
    "- To use with papermill, run `papermill mlflow_experiment.ipynb -p fversion=1 adjust_for_country=0`\n",
    "\n",
    "Limitations:\n",
    "- currently `dutil` only supports \"threads\" Dask scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, make_scorer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, GridSearchCV, cross_validate\n",
    "import dutil.pipeline as dpipe\n",
    "from loguru import logger\n",
    "from pprint import pprint\n",
    "\n",
    "import mlflow_experiment as experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "\n",
    "The pipeline is constructed in `mlflow_experiment.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# --- Global Notebook Parameters ---\n",
    "fversion = 0\n",
    "mversion = 0\n",
    "include_c = False\n",
    "adjust_for_country = True\n",
    "target = 'e'\n",
    "test_ratio = 0.3\n",
    "n_folds = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.params.update_many(dict(\n",
    "    fversion=fversion,\n",
    "    mversion=mversion,\n",
    "    include_c=include_c,\n",
    "    adjust_for_country=adjust_for_country,\n",
    "    target=target,\n",
    "    test_ratio=test_ratio,\n",
    "    n_folds=n_folds,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-25 11:08:58.996 | DEBUG    | dutil.pipeline._cached:dump:200 - Task load_data_3.pickle: data has been saved to cache\n",
      "2020-11-25 11:08:58.997 | DEBUG    | dutil.pipeline._cached:dump:200 - Task load_data_1.pickle: data has been saved to cache\n",
      "2020-11-25 11:08:58.998 | DEBUG    | dutil.pipeline._cached:dump:200 - Task load_data_2.pickle: data has been saved to cache\n",
      "2020-11-25 11:08:58.999 | INFO     | dutil.pipeline._cached:new_foo:319 - Task load_data_3.pickle: data has been computed and saved to cache\n",
      "2020-11-25 11:08:59.000 | INFO     | dutil.pipeline._cached:new_foo:319 - Task load_data_1.pickle: data has been computed and saved to cache\n",
      "2020-11-25 11:08:59.002 | INFO     | dutil.pipeline._cached:new_foo:319 - Task load_data_2.pickle: data has been computed and saved to cache\n",
      "2020-11-25 11:08:59.004 | DEBUG    | dutil.pipeline._cached:__cached_hash__:218 - Task load_data_1.pickle: hash has been computed from data\n",
      "2020-11-25 11:08:59.004 | DEBUG    | dutil.pipeline._cached:__cached_hash__:218 - Task load_data_2.pickle: hash has been computed from data\n",
      "2020-11-25 11:08:59.005 | DEBUG    | dutil.pipeline._cached:__cached_hash__:218 - Task load_data_3.pickle: hash has been computed from data\n",
      "2020-11-25 11:09:00.025 | DEBUG    | dutil.pipeline._cached:dump:200 - Task mlpipe_make_x_y_df_1|9686102406375020340_df_2|1608211821468367081_df_3|16702583620649360787_include_c|False_adjust_for_country|True_target|e_fversion|0.pickle: data has been saved to cache\n",
      "2020-11-25 11:09:00.028 | INFO     | dutil.pipeline._cached:new_foo:319 - Task mlpipe_make_x_y_df_1|9686102406375020340_df_2|1608211821468367081_df_3|16702583620649360787_include_c|False_adjust_for_country|True_target|e_fversion|0.pickle: data has been computed and saved to cache\n",
      "2020-11-25 11:09:00.035 | DEBUG    | dutil.pipeline._cached:__cached_hash__:218 - Task mlpipe_make_x_y_df_1|9686102406375020340_df_2|1608211821468367081_df_3|16702583620649360787_include_c|False_adjust_for_country|True_target|e_fversion|0.pickle: hash has been computed from data\n",
      "2020-11-25 11:09:00.054 | DEBUG    | dutil.pipeline._cached:dump:200 - Task mlpipe_split_x_y_X|17713854509878100511_y|16896747200748431878_test_ratio|0.3.pickle: data has been saved to cache\n",
      "2020-11-25 11:09:00.056 | INFO     | dutil.pipeline._cached:new_foo:319 - Task mlpipe_split_x_y_X|17713854509878100511_y|16896747200748431878_test_ratio|0.3.pickle: data has been computed and saved to cache\n",
      "2020-11-25 11:09:00.061 | DEBUG    | dutil.pipeline._cached:__cached_hash__:218 - Task mlpipe_split_x_y_X|17713854509878100511_y|16896747200748431878_test_ratio|0.3.pickle: hash has been computed from data\n",
      "2020-11-25 11:09:00.144 | DEBUG    | dutil.pipeline._cached:dump:200 - Task mlpipe_crossval_model_model_name|lr_model|Pipeline(steps=(('t', SimpleImputer(fill_value=0)), ('e', LinearRegression())))_X|1095111122033007520_y|805566526682016355_n_folds|2_mversion|0_n_jobs|1.pickle: data has been saved to cache\n",
      "2020-11-25 11:09:00.145 | INFO     | dutil.pipeline._cached:new_foo:319 - Task mlpipe_crossval_model_model_name|lr_model|Pipeline(steps=(('t', SimpleImputer(fill_value=0)), ('e', LinearRegression())))_X|1095111122033007520_y|805566526682016355_n_folds|2_mversion|0_n_jobs|1.pickle: data has been computed and saved to cache\n",
      "2020-11-25 11:09:00.147 | INFO     | mlflow_experiment:run_experiment:136 - Experiment run is finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 'mlpipe_' does not exist. Creating a new experiment\n"
     ]
    }
   ],
   "source": [
    "with experiment.params.context(dict(\n",
    "    model_name='lr',\n",
    "    _model=Pipeline((\n",
    "        ('t', SimpleImputer(fill_value=0)),\n",
    "        ('e', LinearRegression()),\n",
    "    )),\n",
    ")):\n",
    "    model, results = experiment.run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('t', SimpleImputer(fill_value=0)), ('e', LinearRegression())])\n",
      "\n",
      "{'fit_time': array([0.00727439, 0.00400782]),\n",
      " 'score_time': array([0.00246429, 0.00274873]),\n",
      " 'test_mae': array([-2.25, -4.  ]),\n",
      " 'test_r2': array([-19.5, -15. ]),\n",
      " 'train_mae': array([-2.22044605e-16, -1.11022302e-16]),\n",
      " 'train_r2': array([1., 1.])}\n"
     ]
    }
   ],
   "source": [
    "pprint(model)\n",
    "print()\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-25 11:09:21.658 | INFO     | dutil.pipeline._cached:new_foo:304 - Task load_data_1.pickle: skip (cache exists)\n",
      "2020-11-25 11:09:21.659 | INFO     | dutil.pipeline._cached:new_foo:304 - Task load_data_2.pickle: skip (cache exists)\n",
      "2020-11-25 11:09:21.660 | INFO     | dutil.pipeline._cached:new_foo:304 - Task load_data_3.pickle: skip (cache exists)\n",
      "2020-11-25 11:09:21.662 | INFO     | dutil.pipeline._cached:new_foo:304 - Task mlpipe_make_x_y_df_1|9686102406375020340_df_2|1608211821468367081_df_3|16702583620649360787_include_c|False_adjust_for_country|True_target|e_fversion|0.pickle: skip (cache exists)\n",
      "2020-11-25 11:09:21.663 | INFO     | dutil.pipeline._cached:new_foo:304 - Task mlpipe_split_x_y_X|17713854509878100511_y|16896747200748431878_test_ratio|0.3.pickle: skip (cache exists)\n",
      "2020-11-25 11:09:21.667 | DEBUG    | dutil.pipeline._cached:load:186 - Task mlpipe_split_x_y_X|17713854509878100511_y|16896747200748431878_test_ratio|0.3.pickle: data has been loaded from cache\n",
      "2020-11-25 11:09:21.941 | DEBUG    | dutil.pipeline._cached:dump:200 - Task mlpipe_crossval_model_model_name|rf_model|Pipeline(steps=(('t', SimpleImputer(fill_value=0)),\n",
      "                ('e', RandomForestRegressor())))_X|1095111122033007520_y|805566526682016355_n_folds|2_mversion|0_n_jobs|1.pickle: data has been saved to cache\n",
      "2020-11-25 11:09:21.942 | INFO     | dutil.pipeline._cached:new_foo:319 - Task mlpipe_crossval_model_model_name|rf_model|Pipeline(steps=(('t', SimpleImputer(fill_value=0)),\n",
      "                ('e', RandomForestRegressor())))_X|1095111122033007520_y|805566526682016355_n_folds|2_mversion|0_n_jobs|1.pickle: data has been computed and saved to cache\n",
      "2020-11-25 11:09:21.944 | INFO     | mlflow_experiment:run_experiment:136 - Experiment run is finished\n"
     ]
    }
   ],
   "source": [
    "with experiment.params.context(dict(\n",
    "    model_name='rf',\n",
    "    _model=Pipeline((\n",
    "        ('t', SimpleImputer(fill_value=0)),\n",
    "        ('e', RandomForestRegressor()),\n",
    "    )),\n",
    ")):\n",
    "    model, results = experiment.run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fversion': 0, 'mversion': 0, 'include_c': False, 'adjust_for_country': True, 'target': 'e', 'test_ratio': 0.3, 'n_folds': 2, 'model_name': 'rf'}\n"
     ]
    }
   ],
   "source": [
    "with experiment.params.context(dict(\n",
    "    model_name='rf',\n",
    "    _model=RandomForestRegressor(),\n",
    ")):\n",
    "    print(experiment.params.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
