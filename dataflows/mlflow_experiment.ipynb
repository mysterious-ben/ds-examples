{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLFlow Experiment\n",
    "\n",
    "How to efficiently run multiple ML experiments using `dutil` and `mlflow`:\n",
    "- make explicit dependencies between the tasks in the pipeline\n",
    "- run the pipeline with different parameters \n",
    "- record and visualize metrics from multiple runs\n",
    "- cache intermediate data and models\n",
    "\n",
    "About:\n",
    "- See the experiment pipeline: `mlflow_experiment.py`\n",
    "- Show a metrics summary via MLFlow: `mlflow ui` (in the shell)\n",
    "- Run notebooks with different parameters via Papermill: `mlflow_experiment_papermill.ipynb`\n",
    "\n",
    "Limitations:\n",
    "- currently `dutil` only supports \"threads\" Dask scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, make_scorer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, GridSearchCV, cross_validate\n",
    "import dutil.pipeline as dpipe\n",
    "from loguru import logger\n",
    "from pprint import pprint\n",
    "\n",
    "import mlflow_experiment as experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "\n",
    "The pipeline is constructed in `mlflow_experiment.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# --- Global Notebook Parameters ---\n",
    "fversion = 0\n",
    "mversion = 0\n",
    "include_country = True\n",
    "adjust_for_country = True\n",
    "target = 'e'\n",
    "test_ratio = 0.3\n",
    "n_folds = 2\n",
    "_n_jobs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.params.update_many(dict(\n",
    "    fversion=fversion,\n",
    "    mversion=mversion,\n",
    "    include_country=include_country,\n",
    "    adjust_for_country=adjust_for_country,\n",
    "    target=target,\n",
    "    test_ratio=test_ratio,\n",
    "    n_folds=n_folds,\n",
    "    _n_jobs=_n_jobs,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-27 12:45:39.701 | DEBUG    | dutil.pipeline._cached:dump:207 - Task load_data_2.pickle: data has been saved to cache\n",
      "2020-11-27 12:45:39.701 | DEBUG    | dutil.pipeline._cached:dump:207 - Task load_data_1.pickle: data has been saved to cache\n",
      "2020-11-27 12:45:39.702 | DEBUG    | dutil.pipeline._cached:dump:207 - Task load_data_3.pickle: data has been saved to cache\n",
      "2020-11-27 12:45:39.703 | INFO     | dutil.pipeline._cached:new_foo:326 - Task load_data_2.pickle: data has been computed and saved to cache\n",
      "2020-11-27 12:45:39.703 | INFO     | dutil.pipeline._cached:new_foo:326 - Task load_data_1.pickle: data has been computed and saved to cache\n",
      "2020-11-27 12:45:39.704 | INFO     | dutil.pipeline._cached:new_foo:326 - Task load_data_3.pickle: data has been computed and saved to cache\n",
      "2020-11-27 12:45:39.706 | DEBUG    | dutil.pipeline._cached:__cached_hash__:225 - Task load_data_1.pickle: hash has been computed from data\n",
      "2020-11-27 12:45:39.707 | DEBUG    | dutil.pipeline._cached:__cached_hash__:225 - Task load_data_2.pickle: hash has been computed from data\n",
      "2020-11-27 12:45:39.708 | DEBUG    | dutil.pipeline._cached:__cached_hash__:225 - Task load_data_3.pickle: hash has been computed from data\n",
      "2020-11-27 12:45:40.718 | DEBUG    | dutil.pipeline._cached:dump:207 - Task mlpipe_make_x_y_df_1|9686102406375020340_df_2|11371928299187938700_df_3|16702583620649360787_include_country|True_adjust_for_country|True_target|e_fversion|0.pickle: data has been saved to cache\n",
      "2020-11-27 12:45:40.719 | INFO     | dutil.pipeline._cached:new_foo:326 - Task mlpipe_make_x_y_df_1|9686102406375020340_df_2|11371928299187938700_df_3|16702583620649360787_include_country|True_adjust_for_country|True_target|e_fversion|0.pickle: data has been computed and saved to cache\n",
      "2020-11-27 12:45:40.721 | DEBUG    | dutil.pipeline._cached:__cached_hash__:225 - Task mlpipe_make_x_y_df_1|9686102406375020340_df_2|11371928299187938700_df_3|16702583620649360787_include_country|True_adjust_for_country|True_target|e_fversion|0.pickle: hash has been computed from data\n",
      "2020-11-27 12:45:40.726 | DEBUG    | dutil.pipeline._cached:dump:207 - Task mlpipe_split_x_y_X|68681996546272477_y|16896747200748431878_test_ratio|0.3.pickle: data has been saved to cache\n",
      "2020-11-27 12:45:40.727 | INFO     | dutil.pipeline._cached:new_foo:326 - Task mlpipe_split_x_y_X|68681996546272477_y|16896747200748431878_test_ratio|0.3.pickle: data has been computed and saved to cache\n",
      "2020-11-27 12:45:40.729 | DEBUG    | dutil.pipeline._cached:__cached_hash__:225 - Task mlpipe_split_x_y_X|68681996546272477_y|16896747200748431878_test_ratio|0.3.pickle: hash has been computed from data\n",
      "2020-11-27 12:45:40.812 | DEBUG    | dutil.pipeline._cached:dump:207 - Task mlpipe_crossval_model_model_name|lr_X|6317714561027695988_y|805566526682016355_n_folds|2_mversion|0_n_jobs|1.pickle: data has been saved to cache\n",
      "2020-11-27 12:45:40.814 | INFO     | dutil.pipeline._cached:new_foo:326 - Task mlpipe_crossval_model_model_name|lr_X|6317714561027695988_y|805566526682016355_n_folds|2_mversion|0_n_jobs|1.pickle: data has been computed and saved to cache\n",
      "2020-11-27 12:45:40.816 | INFO     | mlflow_experiment:run_experiment:138 - Experiment run is finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 'mlpipe_' does not exist. Creating a new experiment\n"
     ]
    }
   ],
   "source": [
    "with experiment.params.context(dict(\n",
    "    model_name='lr',\n",
    "    _model=Pipeline((\n",
    "        ('t', SimpleImputer(fill_value=0)),\n",
    "        ('e', LinearRegression()),\n",
    "    )),\n",
    ")):\n",
    "    model, results = experiment.run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('t', SimpleImputer(fill_value=0)), ('e', LinearRegression())])\n",
      "\n",
      "{'fit_time': array([0.00814676, 0.00339603]),\n",
      " 'score_time': array([0.00221658, 0.0025723 ]),\n",
      " 'test_mae': array([-1.66666667, -4.        ]),\n",
      " 'test_r2': array([-10.55555556, -15.        ]),\n",
      " 'train_mae': array([-2.22044605e-16, -1.11022302e-16]),\n",
      " 'train_r2': array([1., 1.])}\n"
     ]
    }
   ],
   "source": [
    "pprint(model)\n",
    "print()\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-27 12:45:45.950 | INFO     | dutil.pipeline._cached:new_foo:311 - Task load_data_1.pickle: skip (cache exists)\n",
      "2020-11-27 12:45:45.951 | INFO     | dutil.pipeline._cached:new_foo:311 - Task load_data_2.pickle: skip (cache exists)\n",
      "2020-11-27 12:45:45.952 | INFO     | dutil.pipeline._cached:new_foo:311 - Task load_data_3.pickle: skip (cache exists)\n",
      "2020-11-27 12:45:45.955 | INFO     | dutil.pipeline._cached:new_foo:311 - Task mlpipe_make_x_y_df_1|9686102406375020340_df_2|11371928299187938700_df_3|16702583620649360787_include_country|True_adjust_for_country|True_target|e_fversion|0.pickle: skip (cache exists)\n",
      "2020-11-27 12:45:45.957 | INFO     | dutil.pipeline._cached:new_foo:311 - Task mlpipe_split_x_y_X|68681996546272477_y|16896747200748431878_test_ratio|0.3.pickle: skip (cache exists)\n",
      "2020-11-27 12:45:45.959 | DEBUG    | dutil.pipeline._cached:load:193 - Task mlpipe_split_x_y_X|68681996546272477_y|16896747200748431878_test_ratio|0.3.pickle: data has been loaded from cache\n",
      "2020-11-27 12:45:46.241 | DEBUG    | dutil.pipeline._cached:dump:207 - Task mlpipe_crossval_model_model_name|rf_X|6317714561027695988_y|805566526682016355_n_folds|2_mversion|0_n_jobs|1.pickle: data has been saved to cache\n",
      "2020-11-27 12:45:46.242 | INFO     | dutil.pipeline._cached:new_foo:326 - Task mlpipe_crossval_model_model_name|rf_X|6317714561027695988_y|805566526682016355_n_folds|2_mversion|0_n_jobs|1.pickle: data has been computed and saved to cache\n",
      "2020-11-27 12:45:46.244 | INFO     | mlflow_experiment:run_experiment:138 - Experiment run is finished\n"
     ]
    }
   ],
   "source": [
    "with experiment.params.context(dict(\n",
    "    model_name='rf',\n",
    "    _model=Pipeline((\n",
    "        ('t', SimpleImputer(fill_value=0)),\n",
    "        ('e', RandomForestRegressor()),\n",
    "    )),\n",
    ")):\n",
    "    model, results = experiment.run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fversion': 0, 'mversion': 0, 'include_country': True, 'adjust_for_country': True, 'target': 'e', 'test_ratio': 0.3, 'n_folds': 2, 'model_name': 'rf'}\n"
     ]
    }
   ],
   "source": [
    "with experiment.params.context(dict(\n",
    "    model_name='rf',\n",
    "    _model=RandomForestRegressor(),\n",
    ")):\n",
    "    print(experiment.params.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
